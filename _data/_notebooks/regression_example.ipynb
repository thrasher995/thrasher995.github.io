{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f32b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300eaac1",
   "metadata": {},
   "source": [
    "Step 1: Getting Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10546412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\ML\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Loading boston dataset into a Pandas DataFrame\n",
    "boston_dataset = load_boston()\n",
    "boston_df = pd.DataFrame(boston_dataset[\"data\"], columns=boston_dataset[\"feature_names\"])\n",
    "boston_df[\"target\"] = pd.Series(boston_dataset[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c9a053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing head of DataFrame to make sure the data has been loaded correctly\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5384dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X & Y, where:\n",
    "# X: Feature columns in DataFrame (whatever is needed for predicting)\n",
    "# Y: Column to be predicted\n",
    "X = boston_df.drop('target',axis = 1)\n",
    "Y = boston_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4c12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into test & train sets using train_test_split method:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01895bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((379, 13), (379,), (127, 13), (127,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at shapes to ensure that the dataset was split properly:\n",
    "X_train.shape,Y_train.shape,X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835e14c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([364, 155, 322, 256,  49,  88, 147, 457, 193, 449,\n",
      "            ...\n",
      "             77,  53,  55, 382, 196,  64, 493, 478, 202,  69],\n",
      "           dtype='int64', length=127)\n"
     ]
    }
   ],
   "source": [
    "# Looking at labels in X_test set:\n",
    "print (X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90827db",
   "metadata": {},
   "source": [
    "Step 2: Choosing the Model\n",
    "Done by following the Model Selection Map. In this example, it's a Regression problem.\n",
    "<br>This step involves trying different models.\n",
    "<br>RandomForestRegressor from sklearn.ensemble is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9558d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686d4fd",
   "metadata": {},
   "source": [
    "Step 3: Fitting Model to Data & Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67aa0e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting data to model using fit () method on train sets\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984cf4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using predict() method:\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a02b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a random index from the X_test set\n",
    "random_index = X_test.index[randint(0,X_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467d43ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\ML\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([19.123])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a prediction on a single sample (has to be array)\n",
    "X_test.loc[random_index]\n",
    "model.predict(np.array(X_test.loc[random_index]).reshape(1, -1))\n",
    "# (-1) makes NumPy figure out how many columns this array has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b0163e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         0.21977\n",
       "ZN           0.00000\n",
       "INDUS        6.91000\n",
       "CHAS         0.00000\n",
       "NOX          0.44800\n",
       "RM           5.60200\n",
       "AGE         62.00000\n",
       "DIS          6.08770\n",
       "RAD          3.00000\n",
       "TAX        233.00000\n",
       "PTRATIO     17.90000\n",
       "B          396.90000\n",
       "LSTAT       16.20000\n",
       "Name: 49, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the random element from X_test DF\n",
    "X_test.loc[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60226610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the random element from Y_test Series\n",
    "Y_test.loc[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8259f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM         0.21977\n",
      "ZN           0.00000\n",
      "INDUS        6.91000\n",
      "CHAS         0.00000\n",
      "NOX          0.44800\n",
      "RM           5.60200\n",
      "AGE         62.00000\n",
      "DIS          6.08770\n",
      "RAD          3.00000\n",
      "TAX        233.00000\n",
      "PTRATIO     17.90000\n",
      "B          396.90000\n",
      "LSTAT       16.20000\n",
      "target      19.40000\n",
      "Name: 49, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Printing the random element from boston_df\n",
    "print(boston_df.loc[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5345a52",
   "metadata": {},
   "source": [
    "Step 4: Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f9316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821393581492547"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform .score on train set first:\n",
    "model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f07dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8609444184500319"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform .score on test set:\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8731c",
   "metadata": {},
   "source": [
    "Step 5: Improving Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e147e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accruacy on test set: 0.8551500523556478\n",
      "Cross-validation score: 62.676640626052496%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accruacy on test set: 0.8531991027189121\n",
      "Cross-validation score: 63.11125748931736%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accruacy on test set: 0.8453236834993643\n",
      "Cross-validation score: 62.198481438456476%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accruacy on test set: 0.854997781144057\n",
      "Cross-validation score: 62.65882789101224%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accruacy on test set: 0.8589790129912277\n",
      "Cross-validation score: 60.77470887142453%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accruacy on test set: 0.8492097532613858\n",
      "Cross-validation score: 60.33489428153602%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accruacy on test set: 0.8589825538700473\n",
      "Cross-validation score: 61.11766119895833%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accruacy on test set: 0.8504067960308324\n",
      "Cross-validation score: 61.47367433791968%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accruacy on test set: 0.8566503763642966\n",
      "Cross-validation score: 61.043797605512694%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try different numbers of estimators with cross-validation and no cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestRegressor(n_estimators=i).fit(X_train, Y_train)\n",
    "    print(f\"Model accruacy on test set: {model.score(X_test, Y_test)}\")\n",
    "    print(f\"Cross-validation score: {np.mean(cross_val_score(model, X, Y, cv=5)) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5bac9",
   "metadata": {},
   "source": [
    "Step 6: Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d5c29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save trained model to file\n",
    "pickle.dump(model, open(\"random_forest_model_2.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
